"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ğŸ­  THE QUANT REFINERY  v4.1  â€”  Unified View  ğŸ­              â•‘
â•‘                                                                              â•‘
â•‘  CAMBIO PRINCIPAL v4.1:                                                      â•‘
â•‘    EliminaciÃ³n de st.tabs â†’ flujo vertical Ãºnico.                           â•‘
â•‘    El mÃ³dulo "Radar de Mercado" se integra como SecciÃ³n 4 inline.           â•‘
â•‘    Descarga multi-ticker con fallback individual por activo.                â•‘
â•‘                                                                              â•‘
â•‘  CHANGELOG:                                                                  â•‘
â•‘    v4.1  Unified View. Sin tabs. Radar integrado inline.                    â•‘
â•‘    v4.0  Arquitectura dual (RefinerÃ­a + Radar en tabs).                     â•‘
â•‘    v3.4  Candlestick + subplot Volumen.                                     â•‘
â•‘    v3.2  Fix dtype int64 â†’ float64 en Equity.                              â•‘
â•‘                                                                              â•‘
â•‘  DEPENDENCIAS:                                                               â•‘
â•‘    pandas_ta  â†’  vendorizada en carpeta local (NO pip install)              â•‘
â•‘    yfinance, plotly, xgboost, scikit-learn, pandas, numpy                   â•‘
â•‘                                                                              â•‘
â•‘  ANALOGÃAS INGENIERILES:                                                     â•‘
â•‘    Precios OHLCV     â†’  Materia Prima Cruda                                 â•‘
â•‘    Velas Japonesas   â†’  Diagrama de Fase (T vs P)                           â•‘
â•‘    RSI / BB / MACD   â†’  Sensores del Proceso de Refinado                    â•‘
â•‘    Target            â†’  Vector de Fuerza Predicho                           â•‘
â•‘    XGBoost           â†’  Controlador PID Inteligente                         â•‘
â•‘    CorrelaciÃ³n       â†’  Acoplamiento tÃ©rmico entre sistemas                 â•‘
â•‘    NormalizaciÃ³n     â†’  CalibraciÃ³n a origen comÃºn (Base 100)               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE A â”‚ IMPORTS & CONFIGURACIÃ“N GLOBAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import yfinance as yf
from datetime import datetime, timedelta
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import warnings

# pandas_ta vendorizada: existe como carpeta local, no se instala por pip.
import pandas_ta as ta

warnings.filterwarnings("ignore")

# â”€â”€â”€ Paleta SCADA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CLR_CANDLE_UP   = "#26a69a"   # Verde teal
CLR_CANDLE_DOWN = "#ef5350"   # Rojo coral
CLR_BB          = "rgba(255,255,255,0.30)"
CLR_BB_FILL     = "rgba(255,255,255,0.04)"
CLR_RSI         = "#ffa726"
CLR_MACD        = "#42a5f5"
CLR_MACD_SIG    = "#ab47bc"

# â”€â”€â”€ Benchmarks del Radar (lista fija, el ticker del usuario se agrega) â”€â”€â”€â”€â”€â”€
BENCHMARKS_FIJOS = ["SPY", "QQQ", "BTC-USD", "GLD"]

# â”€â”€â”€ Colores para el grÃ¡fico de rendimiento normalizado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COLORES_RADAR = ["#ffffff", "#42a5f5", "#66bb6a", "#ffa726", "#ef5350"]
# PosiciÃ³n 0 siempre serÃ¡ el ticker del usuario (blanco, lÃ­nea gruesa)

# â”€â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸ­ The Quant Refinery v4.1",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded",
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE B â”‚ CAPA DE DATOS  â€”  Descarga, limpieza, indicadores, target
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _aplanar_multiindex(df: pd.DataFrame) -> pd.DataFrame:
    """
    ğŸ›¡ï¸  Parche universal de MultiIndex para yfinance.

    yfinance puede devolver:
      â€¢ Columnas simples:  ['Open', 'High', 'Low', 'Close', 'Volume']
      â€¢ MultiIndex 1-nivel: [('Close', ''), ('Open', ''), â€¦]
      â€¢ MultiIndex 2-niveles (multi-ticker): [('Close','AAPL'), ('Close','SPY')]

    Este parche detecta el caso y devuelve siempre columnas planas strings.
    """
    if not isinstance(df.columns, pd.MultiIndex):
        df.columns = [str(c).strip() for c in df.columns]
        return df

    # MultiIndex: tomamos el primer nivel (Price) si tiene 2 niveles
    df.columns = df.columns.get_level_values(0)
    df.columns = [str(c).strip() for c in df.columns]

    # Eliminar duplicados (puede pasar si yfinance repite columnas)
    df = df.loc[:, ~df.columns.duplicated(keep="first")]
    return df


def _datos_sinteticos(dias: int) -> pd.DataFrame:
    """Fallback: genera OHLCV sintÃ©ticos (senoidal + browniano)."""
    idx   = pd.date_range(end=datetime.now(), periods=dias, freq="D")
    trend = np.linspace(100, 150, dias)
    wave  = 20 * np.sin(np.linspace(0, 4 * np.pi, dias))
    noise = np.random.randn(dias) * 3
    close = (trend + wave + noise).astype("float32")

    return pd.DataFrame({
        "Open":   (close * 0.995).astype("float32"),
        "High":   (close * 1.015).astype("float32"),
        "Low":    (close * 0.985).astype("float32"),
        "Close":  close,
        "Volume": np.random.randint(1_000_000, 10_000_000, dias).astype("float32"),
    }, index=idx)


@st.cache_data(ttl=3600, show_spinner=False)
def descargar_ticker(ticker: str, dias: int) -> pd.DataFrame:
    """
    ğŸ“¡ Descarga un solo ticker con fallback a sintÃ©ticos.
    Usado para el activo principal Y como fallback individual del Radar.
    """
    end   = datetime.now()
    start = end - timedelta(days=dias)
    try:
        df = yf.download(ticker, start=start, end=end, progress=False)
        if df.empty:
            raise ValueError("respuesta vacÃ­a")
        df = _aplanar_multiindex(df)
        # float32 solo en columnas numÃ©ricas (Type Safety v3.1)
        num = df.select_dtypes(include=["number"]).columns
        df[num] = df[num].astype("float32")
        return df
    except Exception as exc:
        st.warning(f"âš ï¸ Descarga fallida para **{ticker}**: {exc} â†’ modo demo.")
        return _datos_sinteticos(dias)


# â”€â”€â”€ Indicadores tÃ©cnicos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def calcular_indicadores(df: pd.DataFrame) -> pd.DataFrame:
    """
    âš™ï¸  PLANTA DE REFINADO  â€”  pandas_ta (vendorizada).

    Indicadores:
        RSI(14)           Sensor de sobrecalentamiento
        Bollinger(20,2)   LÃ­mites de control
        MACD(12,26,9)     Oscilador de momentum
        Volume_Norm       Volumen / media-20 (bypass si es 0 â†’ Forex)
        Volatility        Rango diario / Close
        Returns           pct_change diario
    """
    data = df.copy()

    # â”€â”€ RSI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    rsi = ta.rsi(data["Close"], length=14)
    if rsi is not None:
        data["RSI"] = rsi

    # â”€â”€ Bollinger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bb = ta.bbands(data["Close"], length=20, std=2)
    if bb is not None:
        data["BB_Lower"]  = bb.iloc[:, 0]
        data["BB_Middle"] = bb.iloc[:, 1]
        data["BB_Upper"]  = bb.iloc[:, 2]

    # â”€â”€ MACD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    macd = ta.macd(data["Close"], fast=12, slow=26, signal=9)
    if macd is not None:
        data["MACD"]        = macd.iloc[:, 0]
        data["MACD_Signal"] = macd.iloc[:, 1]
        data["MACD_Hist"]   = macd.iloc[:, 2]

    # â”€â”€ Volatilidad & Retornos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    data["Volatility"] = (data["High"] - data["Low"]) / data["Close"]
    data["Returns"]    = data["Close"].pct_change()

    # â”€â”€ Volume normalizado (bypass Forex) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "Volume" in data.columns and data["Volume"].sum() > 0:
        vol_med = data["Volume"].rolling(20).mean().replace(0, 1)
        data["Volume_Norm"] = data["Volume"] / vol_med
    else:
        data["Volume_Norm"] = 0.0

    # Infinitos â†’ NaN
    data = data.replace([np.inf, -np.inf], np.nan)

    # float32 en numÃ©ricos
    num = data.select_dtypes(include=["number"]).columns
    data[num] = data[num].astype("float32")
    return data


# â”€â”€â”€ Target + split temporal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FEATURE_COLS = [
    "RSI", "BB_Upper", "BB_Middle", "BB_Lower",
    "MACD", "MACD_Signal", "MACD_Hist",
    "Volatility", "Volume_Norm", "Returns",
]


def preparar_dataset(df: pd.DataFrame, test_pct: int = 20):
    """
    ğŸ¯  Crea Target con .shift(-1)  â†’  prevenciÃ³n de Look-Ahead Bias.

    âš ï¸  CAUSALIDAD TEMPORAL:
        Target[t] = 1  si  Close[t+1] > Close[t]   (precio sube maÃ±ana)
        Target[t] = 0  si  Close[t+1] â‰¤ Close[t]   (precio baja/plato)

        .shift(-1) alinea las etiquetas sin usar datos del futuro durante
        el entrenamiento.  La Ãºltima fila se elimina (target invÃ¡lido).

    Retorna:
        X_train_s, X_test_s, y_train, y_test, scaler, features_usados, df_clean
    """
    data = df.copy()

    # Target
    data["Future_Return"] = data["Close"].pct_change().shift(-1)
    data["Target"]        = (data["Future_Return"] > 0).astype(int)
    data = data.iloc[:-1]  # Ãºltima fila sin target

    # Solo features que efectivamente existen
    features = [f for f in FEATURE_COLS if f in data.columns]

    # Eliminar NaN en features + target
    data = data.dropna(subset=features + ["Target"])

    X = data[features].values.astype("float32")
    y = data["Target"].values

    # â”€â”€ Corte temporal ESTRICTO (sin shuffle) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    split = int(len(X) * (1 - test_pct / 100))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    # NormalizaciÃ³n
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train).astype("float32")
    X_test_s  = scaler.transform(X_test).astype("float32")

    return X_train_s, X_test_s, y_train, y_test, scaler, features, data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE C â”‚ CAPA ML  â€”  XGBoost
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def entrenar_modelo(X_train, y_train, params: dict, device: str = "cpu"):
    """
    ğŸ¤– Controlador PID Inteligente (XGBoost).
        max_bin=256      â†’  OptimizaciÃ³n VRAM para GPU 4 GB (RTX 3050)
        tree_method=hist â†’  Algoritmo eficiente
        device           â†’  'cuda' o 'cpu'; XGBoost cae a CPU si no hay GPU
    """
    model = xgb.XGBClassifier(
        max_depth        = params.get("max_depth", 5),
        learning_rate    = params.get("learning_rate", 0.1),
        n_estimators     = params.get("n_estimators", 100),
        tree_method      = "hist",
        device           = device,
        max_bin          = 256,
        random_state     = 42,
        eval_metric      = "logloss",
        use_label_encoder= False,
    )
    model.fit(X_train, y_train, verbose=False)
    return model


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE D â”‚ FUNCIONES DE GRÃFICOS  â€”  Cada una retorna un go.Figure
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def fig_candlestick(df: pd.DataFrame) -> go.Figure:
    """
    ğŸ•¯ï¸  Velas japonesas con Bandas de Bollinger superpuestas.
        xaxis_rangeslider_visible=False  â†’  sin slider inferior.
    """
    fig = go.Figure()

    fig.add_trace(go.Candlestick(
        x     = df.index,
        open  = df["Open"],
        high  = df["High"],
        low   = df["Low"],
        close = df["Close"],
        name  = "OHLC",
        increasing = dict(line=dict(color=CLR_CANDLE_UP),   fillcolor=CLR_CANDLE_UP),
        decreasing = dict(line=dict(color=CLR_CANDLE_DOWN), fillcolor=CLR_CANDLE_DOWN),
    ))

    if "BB_Upper" in df.columns and "BB_Lower" in df.columns:
        fig.add_trace(go.Scatter(
            x=df.index, y=df["BB_Upper"], mode="lines", name="BB Superior",
            line=dict(color=CLR_BB, width=1, dash="dot"),
        ))
        fig.add_trace(go.Scatter(
            x=df.index, y=df["BB_Lower"], mode="lines", name="BB Inferior",
            line=dict(color=CLR_BB, width=1, dash="dot"),
            fill="tonexty", fillcolor=CLR_BB_FILL,
        ))

    fig.update_layout(
        title="ğŸ•¯ï¸  AnÃ¡lisis de AcciÃ³n de Precio",
        yaxis_title="Precio",
        template="plotly_dark",
        height=520,
        xaxis_rangeslider_visible=False,
        hovermode="x unified",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5),
        margin=dict(l=40, r=30, t=50, b=20),
    )
    return fig


def fig_feature_importance(model, feature_names: list) -> go.Figure:
    """ğŸ“Š Feature Importance â€” barras horizontales."""
    imp = pd.DataFrame({
        "Feature":     feature_names,
        "Importancia": model.feature_importances_,
    }).sort_values("Importancia", ascending=True)

    fig = go.Figure(go.Bar(
        x=imp["Importancia"],
        y=imp["Feature"],
        orientation="h",
        marker=dict(color=imp["Importancia"].tolist(), colorscale="Viridis"),
    ))
    fig.update_layout(
        title="ğŸ§  Feature Importance",
        xaxis_title="Peso relativo",
        template="plotly_dark",
        height=380,
        margin=dict(l=110, r=20, t=45, b=30),
    )
    return fig


def fig_confusion(y_true, y_pred) -> go.Figure:
    """ğŸ¯ Matriz de ConfusiÃ³n â€” Heatmap."""
    cm = confusion_matrix(y_true, y_pred)
    fig = go.Figure(go.Heatmap(
        z=cm,
        x=["Pred: BAJA â–¼", "Pred: SUBE â–²"],
        y=["Real: BAJA â–¼", "Real: SUBE â–²"],
        colorscale="Blues",
        text=cm,
        texttemplate="%{text}",
        textfont=dict(size=22, color="white"),
    ))
    fig.update_layout(
        title="ğŸ¯ Matriz de ConfusiÃ³n",
        template="plotly_dark",
        height=380,
        xaxis=dict(title="PredicciÃ³n"),
        yaxis=dict(title="Realidad", autorange="reversed"),
        margin=dict(l=80, r=20, t=45, b=40),
    )
    return fig


def fig_correlacion(df_retornos: pd.DataFrame) -> go.Figure:
    """
    ğŸ”— CorrelaciÃ³n de retornos diarios (pct_change).
    Se usa pct_change (no precios brutos) para evitar correlaciones espurias.
    """
    corr = df_retornos.corr()
    fig = go.Figure(go.Heatmap(
        z=corr.values,
        x=corr.columns.tolist(),
        y=corr.index.tolist(),
        colorscale="RdBu_r",
        zmid=0,
        text=corr.round(2).values,
        texttemplate="%{text}",
        textfont=dict(size=15),
        colorbar=dict(title="r"),
    ))
    fig.update_layout(
        title="ğŸ”— CorrelaciÃ³n â€” Retornos Diarios",
        template="plotly_dark",
        height=440,
        xaxis=dict(tickangle=20),
        margin=dict(l=60, r=40, t=50, b=50),
    )
    return fig


def fig_rendimiento_normalizado(df_closes: pd.DataFrame, ticker_usuario: str) -> go.Figure:
    """
    ğŸ“ˆ Rendimiento normalizado Base 100.
        valor_norm[t] = (precio[t] / precio[0]) Ã— 100
    La lÃ­nea del usuario: blanco, grosor 3.5, opacidad 1.0.
    El resto: color asignado, grosor 1.8, opacidad 0.55.
    """
    df_norm = (df_closes / df_closes.iloc[0]) * 100

    fig = go.Figure()
    cols_ordenados = [ticker_usuario] + [c for c in df_norm.columns if c != ticker_usuario]

    for i, col in enumerate(cols_ordenados):
        if col not in df_norm.columns:
            continue
        es_usuario = (col == ticker_usuario)
        fig.add_trace(go.Scatter(
            x=df_norm.index,
            y=df_norm[col],
            name=col,
            mode="lines",
            line=dict(
                color = COLORES_RADAR[i % len(COLORES_RADAR)],
                width = 3.5 if es_usuario else 1.8,
            ),
            opacity = 1.0 if es_usuario else 0.55,
        ))

    fig.add_hline(y=100, line_dash="dash", line_color="rgba(255,255,255,0.20)",
                  annotation_text="Base 100")

    fig.update_layout(
        title="ğŸ“ˆ Rendimiento Relativo (Base 100)",
        xaxis_title="Fecha",
        yaxis_title="Valor normalizado",
        template="plotly_dark",
        height=440,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5),
        hovermode="x unified",
        margin=dict(l=50, r=30, t=55, b=40),
    )
    return fig


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE E â”‚ SIDEBAR  â€”  Centro de Control
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.sidebar:
    st.markdown("## ğŸ›ï¸ Centro de Control")
    st.markdown("---")

    # â”€â”€ ğŸ“¡ Activo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ“¡ Activo")
    ticker = st.text_input(
        "Ticker",
        value="BTC-USD",
        placeholder="AAPL, TSLA, BTC-USD â€¦",
        help="Cualquier sÃ­mbolo soportado por Yahoo Finance",
    ).strip().upper()

    periodo_dias = st.slider("DÃ­as histÃ³ricos", 180, 1095, 365, step=30)

    st.markdown("---")

    # â”€â”€ âš™ï¸ XGBoost â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("âš™ï¸ XGBoost")
    max_depth     = st.slider("Max Depth",        3,  10,  5)
    learning_rate = st.slider("Learning Rate (Î·)", 0.01, 0.30, 0.10, step=0.01)
    n_estimators  = st.slider("NÂ° de Ãrboles",   50, 500, 100, step=50)
    test_size     = st.slider("Test Size (%)",   10,  40,  20)

    st.markdown("---")

    # â”€â”€ ğŸ–¥ï¸ Dispositivo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("ğŸ–¥ï¸ Dispositivo")
    device_opt = st.radio("Procesador", ["CPU", "GPU (CUDA)"], index=0,
                          help="GPU requiere driver CUDA compatible")
    device = "cuda" if "GPU" in device_opt else "cpu"

    st.markdown("---")

    # â”€â”€ ğŸš€ BotÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ejecutar = st.button("ğŸš€ EJECUTAR REFINERÃA", type="primary",
                         use_container_width=True)

    st.markdown("---")
    st.caption("ğŸ­ The Quant Refinery v4.1 â€” Unified View")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOQUE F â”‚ PIPELINE PRINCIPAL  â€”  Flujo vertical Ãºnico, sin tabs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.title("ğŸ­ The Quant Refinery v4.1")
st.markdown("*Sistema Adaptativo de Trading AlgorÃ­tmico â€” Unified View*")
st.markdown("---")

if not ejecutar:
    st.info("ğŸ‘† Configura los parÃ¡metros en el sidebar y pulsa **EJECUTAR REFINERÃA**.")
    st.stop()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   SECCIÃ“N 1 â”‚ PROCESAMIENTO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.spinner("ğŸ“¡ Descargando datos del activo â€¦"):
    df_raw = descargar_ticker(ticker, periodo_dias)

with st.spinner("âš™ï¸ Calculando indicadores tÃ©cnicos â€¦"):
    df = calcular_indicadores(df_raw)

with st.spinner("ğŸ¯ Preparando dataset para ML â€¦"):
    (X_train, X_test, y_train, y_test,
     scaler, features_usados, df_clean) = preparar_dataset(df, test_size)

c1, c2, c3 = st.columns(3)
c1.metric("ğŸ“¦ Datos totales",  str(len(df)))
c2.metric("ğŸ‹ï¸ Train",          str(len(y_train)))
c3.metric("ğŸ§ª Test",           str(len(y_test)))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   SECCIÃ“N 2 â”‚ VISUALIZACIÃ“N DE PRECIO  â€”  Velas + Bollinger
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.plotly_chart(fig_candlestick(df), use_container_width=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   SECCIÃ“N 3 â”‚ DIAGNÃ“STICO DEL MODELO  â€”  XGBoost
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.subheader("ğŸ¤– DiagnÃ³stico de IA (XGBoost)")

with st.spinner(f"ğŸ¤– Entrenando modelo en {device.upper()} â€¦"):
    params = {
        "max_depth":     max_depth,
        "learning_rate": learning_rate,
        "n_estimators":  n_estimators,
    }
    model = entrenar_modelo(X_train, y_train, params, device)

y_pred   = model.predict(X_test)
accuracy = (y_pred == y_test).mean() * 100

# KPIs del modelo
m1, m2, m3 = st.columns(3)
m1.metric("ğŸ¯ Accuracy",  f"{accuracy:.2f} %")
m2.metric("ğŸŒ³ Ãrboles",   str(n_estimators))
m3.metric("ğŸ“ Max Depth", str(max_depth))

# â”€â”€ 3 columnas: Reporte â”‚ ConfusiÃ³n â”‚ Feature Importance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
col_rep, col_cm, col_fi = st.columns(3)

with col_rep:
    st.markdown("#### ğŸ“‹ Reporte de ClasificaciÃ³n")
    report = classification_report(
        y_test, y_pred,
        target_names=["BAJA â–¼", "SUBE â–²"],
        output_dict=True,
    )
    st.dataframe(pd.DataFrame(report).T.round(2), use_container_width=True)

    st.markdown("""
    <small>
    <b>Precision:</b> de las predichas positivas, Â¿cuÃ¡ntas fueron correctas?<br>
    <b>Recall:</b> de las realmente positivas, Â¿cuÃ¡ntas las encontrÃ³?<br>
    <b>F1:</b> media armÃ³nica de Precision y Recall.
    </small>""", unsafe_allow_html=True)

with col_cm:
    st.markdown("#### ğŸ¯ Matriz de ConfusiÃ³n")
    st.plotly_chart(fig_confusion(y_test, y_pred), use_container_width=True)

with col_fi:
    st.markdown("#### ğŸ§  Feature Importance")
    st.plotly_chart(fig_feature_importance(model, features_usados), use_container_width=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   SECCIÃ“N 4 â”‚ CONTEXTO GLOBAL & CORRELACIONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   LÃ“GICA DE DESCARGA ROBUSTA (3 niveles de defensa):
#
#   Nivel 1 â†’ yf.download con LISTA de tickers + threads=True
#             Si el resultado tiene MultiIndex (Price, Ticker), extraer
#             'Close' con .xs("Close", level=0, axis=1)
#
#   Nivel 2 â†’ Si Nivel 1 falla, descargar cada ticker INDIVIDUALMENTE
#             con try/except aislado: un activo que falle NO rompe los demÃ¡s.
#
#   Nivel 3 â†’ Si un ticker individual falla, se omite con st.warning
#             y la app continÃºa con los que se descargaron exitosamente.
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")
st.subheader("ğŸ“¡ Contexto Global & Correlaciones")

activos_radar = [ticker] + [b for b in BENCHMARKS_FIJOS if b.upper() != ticker.upper()]

with st.spinner("ğŸ“¡ Descargando benchmarks â€¦"):

    df_closes = None

    # â”€â”€ NIVEL 1: Descarga conjunta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        end   = datetime.now()
        start = end - timedelta(days=periodo_dias)

        df_multi = yf.download(
            activos_radar,
            start=start,
            end=end,
            progress=False,
            threads=True,
        )

        if df_multi.empty:
            raise ValueError("DataFrame vacÃ­o en descarga conjunta")

        # Extraer 'Close' segÃºn estructura de columnas
        if isinstance(df_multi.columns, pd.MultiIndex):
            # Niveles: (Price, Ticker)  â†’  .xs extrae el slice Price=='Close'
            df_closes = df_multi.xs("Close", level=0, axis=1).copy()
        else:
            # Un solo ticker: columnas planas
            if "Close" in df_multi.columns:
                df_closes = df_multi[["Close"]].copy()
                df_closes.columns = [ticker]
            else:
                raise ValueError("columna 'Close' no encontrada en descarga conjunta")

        df_closes.columns = [str(c).strip() for c in df_closes.columns]

    except Exception as exc:
        # â”€â”€ NIVEL 2: Fallback individual por activo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.warning(f"âš ï¸ Descarga conjunta fallida ({exc}). Modo individual â€¦")
        series_dict: dict[str, pd.Series] = {}

        for activo in activos_radar:
            try:                                          # â† NIVEL 3: aislado
                df_tmp = descargar_ticker(activo, periodo_dias)
                if "Close" in df_tmp.columns:
                    series_dict[activo] = df_tmp["Close"]
                else:
                    st.warning(f"âš ï¸ **{activo}**: sin columna 'Close'. Omitido.")
            except Exception as exc2:
                st.warning(f"âš ï¸ **{activo}** fallÃ³: {exc2}. Omitido.")

        if series_dict:
            df_closes = pd.DataFrame(series_dict)
        else:
            st.error("âŒ No se pudo descargar ningÃºn activo. Revisa tu conexiÃ³n.")
            st.stop()

    # â”€â”€ AlineaciÃ³n temporal & dtype â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df_closes = df_closes.dropna()
    df_closes = df_closes.astype("float32")

# â”€â”€ VerificaciÃ³n mÃ­nima â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if df_closes is None or df_closes.empty or len(df_closes) < 2:
    st.error("âŒ No hay suficientes datos alineados para la comparativa.")
    st.stop()

activos_exitosos = df_closes.columns.tolist()
st.info(f"ğŸ“Š Activos cargados: **{', '.join(activos_exitosos)}**  |  "
        f"Fechas alineadas: {len(df_closes)} dÃ­as")

# â”€â”€ VISUALIZACIÃ“N 1: CorrelaciÃ³n (PRIORITARIA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("#### ğŸ”— CorrelaciÃ³n entre activos")

df_retornos = df_closes.pct_change().dropna()
st.plotly_chart(fig_correlacion(df_retornos), use_container_width=True)

st.info("""
**ğŸ“– CÃ³mo leer la matriz:**
- **+1.0 (rojo intenso):** movimiento casi idÃ©ntico â†’ alta sincronÃ­a.
- **0.0 (blanco):** sin relaciÃ³n lineal.
- **âˆ’1.0 (azul intenso):** movimientos opuestos â†’ correlaciÃ³n inversa.

*AnalogÃ­a: dos bloques en contacto tÃ©rmico perfecto (+1) vs dos sistemas
que intercambian calor en sentidos contrarios (âˆ’1).*
""")

# â”€â”€ VISUALIZACIÃ“N 2: Rendimiento normalizado Base 100 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("#### ğŸ“ˆ Rendimiento Relativo")
st.plotly_chart(fig_rendimiento_normalizado(df_closes, ticker), use_container_width=True)

st.info("""
**ğŸ“– CÃ³mo leer el grÃ¡fico:**
Todos los activos empiezan en **100** (= "invertÃ­ 100 unidades el dÃ­a 0").
Si un activo vale **115** â†’ esa inversiÃ³n creciÃ³ un **15 %**.
Si vale **85** â†’ perdiÃ³ un **15 %**.
Esto permite comparar BTC (90 k) vs GLD (2 k) en el mismo eje.
""")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#   FOOTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("---")

with st.expander("ğŸ“š GuÃ­a de Uso"):
    st.markdown("""
    ### ğŸ­ AnalogÃ­as del Sistema

    | Concepto Financiero | AnalogÃ­a Ingenieril |
    |---|---|
    | Precios OHLCV | Materia prima cruda |
    | RSI, Bollinger, MACD | Sensores del proceso de refinado |
    | Target (Sube/Baja) | Vector de fuerza predicho |
    | XGBoost | Controlador PID inteligente |
    | CorrelaciÃ³n | Acoplamiento tÃ©rmico |
    | Base 100 | CalibraciÃ³n a origen comÃºn |

    ### ğŸ¯ InterpretaciÃ³n
    - **Accuracy > 55 %:** el modelo supera al azar (50 %).
    - **Feature Importance alto:** ese indicador pesa mÃ¡s en la decisiÃ³n.
    - **CorrelaciÃ³n +1 â†’ âˆ’1:** sincronÃ­a â†’ movimiento opuesto entre activos.

    ### âš ï¸ Advertencias
    - âŒ NO usar en trading real sin validaciÃ³n exhaustiva.
    - âŒ Resultados pasados NO garantizan resultados futuros.
    - âœ… Herramienta **educativa** para aprender ML aplicado en finanzas.
    """)

st.markdown("---")
st.caption("ğŸ­ The Quant Refinery v4.1 â€” Unified View  |  Streamlit + XGBoost + pandas_ta")
